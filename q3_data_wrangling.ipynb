{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9331d092",
   "metadata": {},
   "source": [
    "# Q3: Data Wrangling\n",
    "\n",
    "**Phase 4:** Data Wrangling & Transformation  \n",
    "**Points: 9 points**\n",
    "\n",
    "**Focus:** Parse datetime columns, set datetime index, extract time-based features.\n",
    "\n",
    "**Lecture Reference:** Lecture 11, Notebook 2 ([`11/demo/02_wrangling_feature_engineering.ipynb`](https://github.com/christopherseaman/datasci_217/blob/main/11/demo/02_wrangling_feature_engineering.ipynb)), Phase 4. Also see Lecture 09 (time series).\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d790dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 182,768 cleaned records\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load cleaned data from Q2\n",
    "df = pd.read_csv('output/q2_cleaned_data.csv')\n",
    "print(f\"Loaded {len(df):,} cleaned records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74c95a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Measurement Timestamp                 Station Name  Air Temperature  \\\n",
      "0   2015-04-25 09:00:00  63rd Street Weather Station             7.00   \n",
      "1   2015-04-30 05:00:00  63rd Street Weather Station             6.10   \n",
      "2   2015-05-22 15:00:00   Oak Street Weather Station            13.70   \n",
      "3   2015-05-22 16:00:00       Foster Weather Station             9.17   \n",
      "4   2015-05-22 17:00:00   Oak Street Weather Station            13.70   \n",
      "\n",
      "   Wet Bulb Temperature  Humidity  Rain Intensity  Interval Rain  Total Rain  \\\n",
      "0                   5.9        86             7.2            5.0         5.2   \n",
      "1                   4.3        76             0.0            0.0         2.5   \n",
      "2                   7.0        55             0.0            0.0         1.4   \n",
      "3                  11.6        59             0.0            0.0        55.5   \n",
      "4                   6.3        56             0.0            0.0         1.4   \n",
      "\n",
      "   Precipitation Type  Wind Direction  Wind Speed  Maximum Wind Speed  \\\n",
      "0                60.0             119         5.1                 7.1   \n",
      "1                 0.0              11         7.2                13.0   \n",
      "2                 0.0              63         1.9                 2.8   \n",
      "3                 0.0               4         4.0                 4.4   \n",
      "4                 0.0             124         1.5                 2.3   \n",
      "\n",
      "   Barometric Pressure  Solar Radiation  Heading  Battery Life  \\\n",
      "0                986.1               38    354.0          12.0   \n",
      "1                989.9                4    354.0          11.9   \n",
      "2                994.4              780    322.0          12.0   \n",
      "3                994.4              556    354.0          15.1   \n",
      "4                994.4              180    322.0          12.1   \n",
      "\n",
      "  Measurement Timestamp Label                        Measurement ID  \n",
      "0          04/25/2015 9:00 AM  63rdStreetWeatherStation201504250900  \n",
      "1          04/30/2015 5:00 AM  63rdStreetWeatherStation201504300500  \n",
      "2          05/22/2015 3:00 PM   OakStreetWeatherStation201505221500  \n",
      "3          05/22/2015 4:00 PM      FosterWeatherStation201505221600  \n",
      "4          05/22/2015 5:00 PM   OakStreetWeatherStation201505221700  \n"
     ]
    }
   ],
   "source": [
    "# Generate output/q3_wrangled_data.csv\n",
    "df_clean = df.copy()\n",
    "df_clean['Measurement Timestamp'] = pd.to_datetime(df_clean['Measurement Timestamp'])\n",
    "df_clean = df_clean.sort_values('Measurement Timestamp')\n",
    "df_clean.set_index('Measurement Timestamp', inplace = True)\n",
    "df_clean.reset_index(inplace = True)\n",
    "df_clean.to_csv('output/q3_wrangled_data.csv', index = False)\n",
    "\n",
    "print(df_clean.head())\n",
    "                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a8668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output/q3_temporal_features.csv\n",
    "df_clean['Measurement Timestamp'] = pd.to_datetime(df_clean['Measurement Timestamp'])\n",
    "temporal_df = pd.DataFrame()\n",
    "temporal_df['Measurement Timestamp'] = df_clean['Measurement Timestamp']\n",
    "\n",
    "temporal_df['hour'] = temporal_df['Measurement Timestamp'].dt.hour\n",
    "temporal_df['day_of_week']= temporal_df['Measurement Timestamp'].dt.dayofweek\n",
    "temporal_df['month'] = temporal_df['Measurement Timestamp'].dt.month\n",
    "temporal_df['year'] = temporal_df['Measurement Timestamp'].dt.year\n",
    "temporal_df['day_name'] = temporal_df['Measurement Timestamp'].dt.day_name()\n",
    "temporal_df['is_weekend'] = temporal_df['day_of_week'].apply(lambda x: 1 if x >=5 else 0)\n",
    "\n",
    "temporal_df.to_csv('output/q3_temporal_features.csv', index = False)\n",
    "\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "308d04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output/q3_datetime_info.txt\n",
    "df_clean['Measurement Timestamp'] = pd.to_datetime(df_clean['Measurement Timestamp'])\n",
    "start = df_clean['Measurement Timestamp'].min()\n",
    "end = df_clean['Measurement Timestamp'].max()\n",
    "\n",
    "total_duraction = end - start\n",
    "\n",
    "years = total_duraction.days // 365\n",
    "months = (total_duraction.days % 365) // 30\n",
    "days = (total_duraction.days % 365) % 30\n",
    "hours = total_duraction.seconds // 3600\n",
    "\n",
    "with open('output/q3_datetime_info.txt', 'w') as f:\n",
    "    f.write(\"Date Range After Datetime Parsing:\\n\")\n",
    "    f.write(f\"Start: {start}\\n\")\n",
    "    f.write(f\"End: {end}\\n\")\n",
    "    f.write(f\"Duration: {years} years, {months} months, {days} days, {hours} hours\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71d8451",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Parse datetime columns, set datetime index, and extract temporal features for time series analysis.\n",
    "\n",
    "**Time Series Note:** This dataset is time-series data (sensor readings over time), unlike the lecture's event-based taxi data. You'll work with a datetime index and extract temporal features (hour, day_of_week, month) that are essential for time series analysis. See **Lecture 09** for time series operations. Use pandas datetime index properties (`.hour`, `.dayofweek`, `.month`, etc.) to extract temporal features from your datetime index.\n",
    "\n",
    "---\n",
    "\n",
    "## Required Artifacts\n",
    "\n",
    "You must create exactly these 3 files in the `output/` directory:\n",
    "\n",
    "### 1. `output/q3_wrangled_data.csv`\n",
    "**Format:** CSV file\n",
    "**Content:** Dataset with datetime index set\n",
    "**Requirements:**\n",
    "- Datetime column parsed using `pd.to_datetime()`\n",
    "- Datetime column set as index using `df.set_index()`\n",
    "- Index sorted chronologically using `df.sort_index()`\n",
    "- **When saving:** Reset index to save datetime as column: `df.reset_index().to_csv(..., index=False)`\n",
    "- All original columns preserved\n",
    "- **No extra index column** (save with `index=False`)\n",
    "\n",
    "### 2. `output/q3_temporal_features.csv`\n",
    "**Format:** CSV file\n",
    "**Required Columns (exact names):** Must include at minimum:\n",
    "- Original datetime column (e.g., `Measurement Timestamp` or `datetime`)\n",
    "- `hour` (integer, 0-23)\n",
    "- `day_of_week` (integer, 0=Monday, 6=Sunday)\n",
    "- `month` (integer, 1-12)\n",
    "\n",
    "**Optional but recommended:**\n",
    "- `year` (integer)\n",
    "- `day_name` (string, e.g., \"Monday\")\n",
    "- `is_weekend` (integer, 0 or 1)\n",
    "\n",
    "**Content:** DataFrame with datetime column and extracted temporal features\n",
    "**Requirements:**\n",
    "- At minimum: datetime column, `hour`, `day_of_week`, `month`\n",
    "- All values must be valid (no NaN in required columns)\n",
    "- **No index column** (save with `index=False`)\n",
    "\n",
    "**Example columns:**\n",
    "```csv\n",
    "Measurement Timestamp,hour,day_of_week,month,year,day_name,is_weekend\n",
    "2022-01-01 00:00:00,0,5,1,2022,Saturday,1\n",
    "2022-01-01 01:00:00,1,5,1,2022,Saturday,1\n",
    "...\n",
    "```\n",
    "\n",
    "### 3. `output/q3_datetime_info.txt`\n",
    "**Format:** Plain text file\n",
    "**Content:** Date range information after datetime parsing\n",
    "**Required information:**\n",
    "- Start date (earliest datetime)\n",
    "- End date (latest datetime)\n",
    "- Total duration (optional but recommended)\n",
    "\n",
    "**Example format:**\n",
    "```\n",
    "Date Range After Datetime Parsing:\n",
    "Start: 2022-01-01 00:00:00\n",
    "End: 2027-09-15 07:00:00\n",
    "Total Duration: 5 years, 8 months, 14 days, 7 hours\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements Checklist\n",
    "\n",
    "- [ ] Datetime columns parsed correctly using `pd.to_datetime()`\n",
    "- [ ] Datetime index set using `df.set_index()`\n",
    "- [ ] Index sorted chronologically using `df.sort_index()`\n",
    "- [ ] Temporal features extracted: `hour`, `day_of_week`, `month` (minimum)\n",
    "- [ ] All 3 required artifacts saved with exact filenames\n",
    "\n",
    "---\n",
    "\n",
    "## Your Approach\n",
    "\n",
    "1. **Parse datetime** - Convert datetime column using `pd.to_datetime()`\n",
    "2. **Set datetime index** - Set as index and sort chronologically\n",
    "3. **Extract temporal features** - Use datetime index properties (`.hour`, `.dayofweek`, `.month`, etc.)\n",
    "4. **Save artifacts** - Remember to `reset_index()` before saving CSVs so the datetime becomes a column\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Points\n",
    "\n",
    "- **Datetime parsing:** What format is your datetime column? Use `pd.to_datetime()` with appropriate format string if needed: `pd.to_datetime(df[col], format='%Y-%m-%d %H:%M:%S')`\n",
    "- **Temporal features:** Extract at minimum: hour, day_of_week, month. Consider also: year, day_name, is_weekend, time_of_day categories. What makes sense for your analysis?\n",
    "\n",
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "After Q3, you should have:\n",
    "- [ ] Datetime columns parsed\n",
    "- [ ] Datetime index set and sorted\n",
    "- [ ] Temporal features extracted (at minimum: hour, day_of_week, month)\n",
    "- [ ] All 3 artifacts saved: `q3_wrangled_data.csv`, `q3_temporal_features.csv`, `q3_datetime_info.txt`\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Continue to `q4_feature_engineering.md` for Feature Engineering.\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
